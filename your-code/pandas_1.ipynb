{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas Lab\n",
    "\n",
    "Complete the following set of exercises to solidify your knowledge of Pandas fundamentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Numpy and Pandas and alias them to `np` and `pd` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Pandas Series containing the elements of the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [5.7, 75.2, 74.4, 84.0, 66.5, 66.3, 55.8, 75.7, 29.1, 43.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5.7\n",
      "1    75.2\n",
      "2    74.4\n",
      "3    84.0\n",
      "4    66.5\n",
      "5    66.3\n",
      "6    55.8\n",
      "7    75.7\n",
      "8    29.1\n",
      "9    43.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x = pd.Series([5.7, 75.2, 74.4, 84.0, 66.5, 66.3, 55.8, 75.7, 29.1, 43.7]) \n",
    "print(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use indexing to return the third value in the Series above.\n",
    "\n",
    "*Hint: Remember that indexing begins at 0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m third_value \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(third_value )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "third_value = res.iloc[2]\n",
    "print(third_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a Pandas DataFrame from the list of lists below. Each sublist should be represented as a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1     2     3     4     5\n",
      "0  53.1  95.0  67.5  35.0  78.4\n",
      "1  61.3  40.8  30.8  37.8  87.6\n",
      "2  20.6  73.2  44.2  14.6  91.8\n",
      "3  57.4   0.1  96.1   4.2  69.5\n",
      "4  83.6  20.5  85.4  22.8  35.9\n",
      "5  49.0  69.0   0.1  31.8  89.1\n",
      "6  23.3  40.7  95.0  83.8  26.9\n",
      "7  27.6  26.4  53.8  88.8  68.5\n",
      "8  96.6  96.4  53.4  72.4  50.1\n",
      "9  73.7  39.0  43.2  81.6  34.7\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(b)\n",
    "df.columns = [\"1\", \"2\", \"3\", \"4\", \"5\"] \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Rename the data frame columns based on the names in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score_1  Score_2  Score_3  Score_4  Score_5\n",
      "0     53.1     95.0     67.5     35.0     78.4\n",
      "1     61.3     40.8     30.8     37.8     87.6\n",
      "2     20.6     73.2     44.2     14.6     91.8\n",
      "3     57.4      0.1     96.1      4.2     69.5\n",
      "4     83.6     20.5     85.4     22.8     35.9\n",
      "5     49.0     69.0      0.1     31.8     89.1\n",
      "6     23.3     40.7     95.0     83.8     26.9\n",
      "7     27.6     26.4     53.8     88.8     68.5\n",
      "8     96.6     96.4     53.4     72.4     50.1\n",
      "9     73.7     39.0     43.2     81.6     34.7\n"
     ]
    }
   ],
   "source": [
    "# تحويل القائمة إلى DataFrame\n",
    "df = pd.DataFrame(b, columns=[\"Score_1\", \"Score_2\", \"Score_3\", \"Score_4\", \"Score_5\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a subset of this data frame that contains only the Score 1, 3, and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score_1  Score_2  Score_3\n",
      "0     53.1     95.0     67.5\n",
      "1     61.3     40.8     30.8\n",
      "2     20.6     73.2     44.2\n",
      "3     57.4      0.1     96.1\n",
      "4     83.6     20.5     85.4\n",
      "5     49.0     69.0      0.1\n",
      "6     23.3     40.7     95.0\n",
      "7     27.6     26.4     53.8\n",
      "8     96.6     96.4     53.4\n",
      "9     73.7     39.0     43.2\n"
     ]
    }
   ],
   "source": [
    "subset_df = df[[\"Score_1\", \"Score_2\", \"Score_3\"]]\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. From the original data frame, calculate the average Score_3 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score_3: 56.95000000000001\n"
     ]
    }
   ],
   "source": [
    "average_score_3 = df[\"Score_3\"].mean()\n",
    "print(\"Average Score_3:\", average_score_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. From the original data frame, calculate the maximum Score_4 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Score_4: 88.8\n"
     ]
    }
   ],
   "source": [
    "max_score_4 = df[\"Score_4\"].max()\n",
    "print(\"Maximum Score_4:\", max_score_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. From the original data frame, calculate the median Score 2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Score 2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Score 2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m median_score_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mScore 2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_score_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Score 2'"
     ]
    }
   ],
   "source": [
    "median_score_2 = df['Score 2'].median()\n",
    "print(\"median_score_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create a Pandas DataFrame from the dictionary of product orders below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {'Description': ['LUNCH BAG APPLE DESIGN',\n",
    "  'SET OF 60 VINTAGE LEAF CAKE CASES ',\n",
    "  'RIBBON REEL STRIPES DESIGN ',\n",
    "  'WORLD WAR 2 GLIDERS ASSTD DESIGNS',\n",
    "  'PLAYING CARDS JUBILEE UNION JACK',\n",
    "  'POPCORN HOLDER',\n",
    "  'BOX OF VINTAGE ALPHABET BLOCKS',\n",
    "  'PARTY BUNTING',\n",
    "  'JAZZ HEARTS ADDRESS BOOK',\n",
    "  'SET OF 4 SANTA PLACE SETTINGS'],\n",
    " 'Quantity': [1, 24, 1, 2880, 2, 7, 1, 4, 10, 48],\n",
    " 'UnitPrice': [1.65, 0.55, 1.65, 0.18, 1.25, 0.85, 11.95, 4.95, 0.19, 1.25],\n",
    " 'Revenue': [1.65, 13.2, 1.65, 518.4, 2.5, 5.95, 11.95, 19.8, 1.9, 60.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders = {\n",
    "    'Description': ['LUNCH BAG APPLE DESIGN', 'SET OF 60 VINTAGE LEAF CAKE CASES', 'RIBBON REEL STRIPES DESIGN', 'WORLD WAR 2 GLIDERS ASSTD DESIGNS', 'PLAYING CARDS JUBILEE UNION JACK', 'POPCORN HOLDER', 'PARTY BUNTING', 'JAZZ HEARTS ADDRESS BOOK', 'SET OF 4 SANTA PLACE SETTINGS'],\n",
    "    'Quantity': [1, 24, 1, 2880, 2, 7, 4, 10, 48],\n",
    "    'UnitPrice': [1.65, 0.55, 1.65, 0.85, 11.95, 4.95, 0.19, 1.9, 1.25],\n",
    "    'Revenue': [1.65, 13.2, 1.65, 518.4, 23.9, 34.65, 0.76, 19.0, 60.0]\n",
    "}\n",
    "\n",
    "df_orders = pd.DataFrame(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calculate the total quantity ordered and revenue generated from these orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Quantity Ordered: 2977\n",
      "Total Revenue Generated: 673.21\n"
     ]
    }
   ],
   "source": [
    "total_quantity = df_orders['Quantity'].sum()\n",
    "total_revenue = df_orders['Revenue'].sum()\n",
    "print(\"Total Quantity Ordered:\",total_quantity)\n",
    "print(\"Total Revenue Generated:\",total_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Obtain the prices of the most expensive and least expensive items ordered and print the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load another dataset for more exercisesº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "admissions = pd.read_csv('../Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the dataset by looking at the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "0           1        337          118                  4  4.5   4.5  9.65   \n",
      "1           2        316          104                  3  3.0   3.5  8.00   \n",
      "2           3        322          110                  3  3.5   2.5  8.67   \n",
      "3           4        314          103                  2  2.0   3.0  8.21   \n",
      "4           5        330          115                  5  4.5   3.0  9.34   \n",
      "\n",
      "   Research  Chance of Admit   \n",
      "0         1              0.92  \n",
      "1         1              0.72  \n",
      "2         1              0.80  \n",
      "3         0              0.65  \n",
      "4         1              0.90  \n"
     ]
    }
   ],
   "source": [
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Before beginning to work with this dataset and evaluating graduate admissions data, we will verify that there is no missing data in the dataset. Do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial No.           0\n",
      "GRE Score            0\n",
      "TOEFL Score          0\n",
      "University Rating    0\n",
      "SOP                  0\n",
      "LOR                  0\n",
      "CGPA                 0\n",
      "Research             0\n",
      "Chance of Admit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = admissions.isnull().sum()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2 -  Interestingly, there is a column that uniquely identifies the applicants. This column is the serial number column. Instead of having our own index, we should make this column our index. Do this in the cell below. Keep the column in the dataframe in addition to making it an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# تعيين عمود serial number كـ index دون حذفه\n",
    "admissions.set_index('Serial No.', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that `GRE Score` and `CGPA` also uniquely identify the data. Show this in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - In this part of the lab, we would like to test complex conditions on the entire data set at once. Let's start by finding the number of rows where the CGPA is greater than 9 and the student has performed an investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 101\n"
     ]
    }
   ],
   "source": [
    "# حساب عدد الصفوف حيث الـ CGPA أكبر من 9 والطالب أجرى تحقيقًا\n",
    "filtered_rows = admissions[(admissions['CGPA'] > 9) & (admissions['Research'] == 1)]\n",
    "num_rows = filtered_rows.shape[0]\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Now return all the rows where the CGPA is greater than 9 and the SOP score is less than 3.5. Find the mean chance of admit for these applicants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Chance of Admit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Chance of Admit'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m filtered_rows_2 \u001b[38;5;241m=\u001b[39m admissions[(admissions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCGPA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m9\u001b[39m) \u001b[38;5;241m&\u001b[39m (admissions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSOP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3.5\u001b[39m)]\n\u001b[1;32m----> 2\u001b[0m mean_chance \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_rows_2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mChance of Admit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\arwa0\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Chance of Admit'"
     ]
    }
   ],
   "source": [
    "filtered_rows_2 = admissions[(admissions['CGPA'] > 9) & (admissions['SOP'] < 3.5)]\n",
    "mean_chance = filtered_rows_2['Chance of Admit'].mean()  # تأكدي من أن الاسم صحيح هنا"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
